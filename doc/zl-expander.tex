%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt,english,letterpaper]{article}
\usepackage{pslatex}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
%\usepackage{geometry}
%\geometry{letterpaper,dvips,
%          top=1in,
%          bottom=1in,
%          left=1.5in,
%          right=1.5in}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{mdwlist}

% Note: when changing spacing also change to code macro below
%\singlespacing
\onehalfspacing
%\doublespacing
\setlength\parskip{\bigskipamount}
\setlength\parindent{0pt}

\IfFileExists{url.sty}{\usepackage{url}}
                      {\newcommand{\url}{\texttt}}
\usepackage{hyperref}

\special{papersize=8.5in,11in}
\pdfpageheight\paperheight
\pdfpagewidth\paperwidth

\makeatletter
\usepackage{babel}
\makeatother

\DefineVerbatimEnvironment
  {code}{Verbatim}{baselinestretch=1,xleftmargin=2ex,fontsize=\small}

\newcommand{\subs}[1]{$_{#1}$}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{The ZL Parser and Macro Expander}
\author{Kevin Atkinson}

\section{Overview}

Parsing a source file in ZL is a three step process.  In the first
step a string of characters in converted to a syntax object, in other
words a string is parsed into a syntax object.  The grammar is
specified as a PEG and a Packrat parser is used to convert the string of
characters to a syntax object.  The second step is the expander, in
this step syntax objects are manipulated into other syntax objects.
It is here where macros are expanded.  Finally, in the third step
syntax objects are converted in an AST.  However, these three steps
are deeply intertwined.

The process starts by performing an initial parse of the source code
into a syntax object using the Packrat parser.  This initial parse
serves to separate the source code in separate declarations.  It does
not fully parse the code, in particular anything between grouping
characters "()", "\{\}", and "[]" is only minimally parsed to match
grouping characters and returned as an unparsed string.

The syntax object returned after this is essentially a list of
declarations.  Each declaration is converted into an AST object and
added to the environment.  In order to do this it is necessary to partly
expand the syntax object to expand any macros and perform any other
necessary transformations.  The partial expansion will expand just
enough to expose the top level form so we know what type of AST object
it needs to be converted to.

Once the top level form is exposed, it is converted into an AST
object.  During the conversion each of its parts is also converted to
an AST.  This conversion thus involves partly expanding the source
code.  Thus as a syntax object is converted into an AST it is expanded
as necessary, which means at no point during the expansion process is
a completely expanded syntax object available.

\section{The Initial Parse \& Top Level Grammar}

The expansion/parsing process starts out by performing an initial
parse of the source code into a syntax object using the Packrat parser
using something like\footnote{For the complete grammar see ...} the
following grammar:

\begin{code}[fontsize=\small]
TOP = <top> SPACING {STMT}+;

STMT : "statement" = 
      <<mid>> {MID} ";"
    / <if>    "if" "(" {EXP} ")" {STMT} ("else" {STMT})?
    / <while> "while" "(" {EXP} ")" {STMT}
    / <break>    "break" ";"
    / <continue> "continue" ";"
    / <return>   "return" {EXP} ";"
    # other statements ...
    / <stmt>   ({TOKEN_}+ {PARAN} {BRACE} / {TOKEN}+ ";")
   ;

EXP = <exp> {TOKEN}+;

TOKEN_ : "token_" =  
      <<mid>> {MID} / {BRACK} / {CONST} / <id> {ID} / <sym> {SYM};
TOKEN : "token" = TOKEN_ / PARAN;

PARAN = <()> "(" {RAW_TOKEN*} ")";
BRACE = <{}> "{" {RAW_TOKEN*} "}";
BRACK = <[]> "[" {RAW_TOKEN*} "]";

CONST = <float> ...  / <literal> ... / <string> ... / <char> ...

ID : "identifier" =
  <<mid>> {MID} / {[@$\a_][\a_\d]*} SPACING;

SYM : "symbol" = {'...' / '==' / '+' / ...} SPACING;

RAW_TOKEN = STRING / CHAR / BRACE / PARAN / BRACK / COMMENT / [^\)\]\}];

STRING = '"' ('\\'_/[^"])+ '"' SPACING;
CHAR   = '\'' ('\\'_/[^'])+ '\'' SPACING;

SPACING : "spacing" = [\s]* COMMENT?;

COMMENT = ...;
\end{code}

In this grammar specification the standard Packrat operators are
supported.  That is, given any existing parsing expressions e, e1, and
e2, a new parsing expression can be constructed using the following
operators:
\begin{itemize*}
\item Grouping: (e)
\item Literal string: ' '
\item Literal string: " "
\item Character class: [ ]
\item Any character: \_
\item Optional: e?
\item Zero-or-more: e*
\item One-or-more: e+
\item And-predicate: \&e
\item Not-predicate: !e
\item Sequence: e1 e2
\item Ordered choice: e1 / e2
\end{itemize*}
as well as some additional operators for constructing syntax objects:
\begin{itemize*}
\item Capture: \{e\}
\item Named Capture: <> e
\end{itemize*}

The capture operators are used for constructing syntax objects in the
obvious ways.  The special \verb/<<mid>>/ operator and \verb/MID/
production will be explained latter.

The grammar serves to separate individual statements and declarations
and to recognize forms which are convenient to do using a Packrat
parser.  As noted earlier, it does not fully parse the code.  In
particular anything between grouping characters "()", "\{\}", and "[]"
is only minimally parsed to match grouping characters and returned as
an unparsed string.  In addition declarations and expressions are not
parsed at this point, and are represented as a list of tokens.

For example the program:

\begin{code}
int x = 20;

int main() {
  x = x + 5;
  return x;
}
\end{code}

will become

\begin{code}
(top 
  (stmt (id int) (id x) (sym =) (literal 5))
  (stmt (id int) (id main) ("()") ("{}" "x = x + 5; return x;")))
\end{code}

Next the individual statements are converted to an AST, partly
expanding as necessary.

\section{The Conversion to an AST \& The Partial Expander}

After the initial parse each statement is converted into an AST object
and added to the environment.  In order to do this it is necessary to
partly expand the syntax object to expand any macros and perform any
other necessary transformations.  The partial expansion will expand just
enough to expose the top level form so we know what type of AST object
it needs to be converted to.

In addition to normal macros the partial expander handles several
special forms which could be considered macros since it converts
from one syntax object to another.  These forms are ``stmt'', ``exp'',
``()'', ``[]'', and ``\{\}''.

The ``stmt'' macro recognizes declarations and expressions.  First the
declarations expander is tried and if that fails the expression
expander is tried.  These are necessary because the current PEG
grammar does not necessarily return a valid top-level form.  It will
only recognize block structures such as "if" and "while" forms.  It
will not recognize functions, variable declarations and expressions.
The reason for this is primarily pragmatic.  Correctly parsing C and
C++ declarations involves maintaining state.  This is inherently
incompatible with Packrat parsing while grammar for expressions
generally involves left-recursion, again incompatible with Packrat
parsing.  With work both of these problems can be addressed in the
Packrat parser.  It is possible to have limited state....  It is also
fairly straightforward to convert a grammar with left-recursion to one
that is not....  In addition it is even possible to modify the Packrat
parser to support left recursion...  Nevertheless, I chose to avoid
these two issues completely by using a PEG grammar which essentially
parses a statement into a list of tokens if it not a not a recognized
block structure.  I use the term "tokens" loosely here, since anything
inside of a ``()'', ``\{\}'', or ``[]'' is treated as one token.  As
with everything else both these expander do not fully expand the
``stmt''.  For example the statement:
\begin{code}
x = (x + 1) * 2;
\end{code}
will first get parsed as:
\begin{code}
(stmt (id x) (sym =) ("()" "x + 1") (sym *) (literal 2))
\end{code}
which will become:
\begin{code}
(assign (id x) (times ("()" "x + 1") (literal 2)))
\end{code}
with the \verb/(x + 1)/ left unparsed.

The ``exp'' macro is like the ``stmt'' macro but only the expression
expander is tried.

The other two macros ``()'', ``[]'', and ``\{\}'' macros are used for
reparsing strings.  The ``()'' and ``[]'' macros reparses the string
as an expression using the ``EXP'' production in the grammar, while
the ``\{\}'' reparses the string as a list of statements using the
``SLIST'' production which is as follows:
\begin{code}
SLIST = <@> SPACING {STMT}+;
\end{code}
The ``@'' means ``list of'' which becomes a list of AST nodes. 

If the syntax object is not one of the previously mentioned special
forms than normal macro expansion is tried.  Macros can be in one of
three forms. 1) Syntax macros which can be considered new syntax
forms.  These forms generally come from new PEG productions but can
also be the results of other macros.  Syntax macros are of the form
\verb/(XXX ...)/ where \verb/XXX/ is the macro name.  2) Function call
macros which have the form \verb/(call XXX ("()" "..."))/, and 3)
Identifier macros which have the form \verb/(id XXX)/.  No matter what
form the macro is in, the mechanism of expansion is the same, and
will be described in the next section.

If any expansion is done the process is repeated on the result of the
expansion.  If there is no expansion the syntax object is assumed to
represent a primitive and is converted into an AST node or list of AST
nodes in the case of a ``@''.  During the conversion to an AST node
the individual parts will be partly expanded as necessary, thus
repeating the process and eventually fully expanding the source code.
However, the end result is a AST tree and not a fully expanded syntax
object.

\section{Macros}
\label{macros}

A macro is a normal function which takes in syntax object and an
environment, and returns a transformed syntax object.  It transforms the
syntax object via call back functions.  The core Macro API consists of:
\begin{itemize*}
\item the types:
\begin{itemize*}
\item UnmarkedSyntax
\item Syntax
\item Match
\item Mark
\end{itemize*}
\item the call back functions:
\begin{itemize*}
\item \verb/Match * match_args(Match *, UnmarkedSyntax * pattern, Syntax * with)/
\item \verb/Syntax * replace(UnmarkedSyntax *, Match *, Mark *)/
\end{itemize*}
\item and syntax forms:
\begin{itemize*}
\item \verb/new_mark()/ -- returns \verb/Mark */
\item \verb/syntax (...)|{...}|ID/ -- returns \verb/UnmarkedSyntax */
\item \verb/raw_syntax (...)/ -- returns \verb/UnmarkedSyntax */
\item \verb/make_syntax_macro [ID] [ID];/
\item \verb/make_macro ID [ID];/
\end{itemize*}
\end{itemize*}

One of the most important parts of a macro is the ability to create new
syntax.  This is done using the \verb/syntax/ and \verb/raw_syntax/
primitive.  Exactly what type of syntax object is created depends on
which form is used.  For the \verb/syntax/ forms, it is as follows:
\begin{description}
\item[\texttt{syntax (...)}] a ``()'', which generally parsed as an expression
\item[\texttt{syntax \{...\}}] a ``\{\}'', which is generally parsed as an statement block
\item[\texttt{syntax ID}] an identifier
\end{description}
The \verb/raw_syntax/ directly creates a syntax object without any
additional reparsing.  That is
\verb/raw_syntax (times (id x) (literal 2))/ creates exactly that,
which is almost the same as \verb/syntax (x * 2)/ but it first gets
parsed as \verb/("()" "x * 2")/ and than latter gets transformed to
\verb/(times (id x) (literal 2)/.

Creating syntax alone is not very useful without being able to perform
substitution on pattern variables.  This is what the ``match'' and
``replace'' function is for.  The ``match'' function is used to
decompose the input by matching pattern variables, the second
parameter, with the arguments of the macro, the third
parameter.  (The first argument, which will be explained latter, is
generally null).  The ``replace'' function is used to rebuild the
output by matching the passed in syntax object, the first parameter,
and generally created with ``syntax'', with the pattern variables
in the ``Match'' object, the second parameter.  However, syntax
objects created with ``syntax'' do not have any lexical information
associated with them, in other words they are unmarked.  Thus it is
necessary to attach lexical information to them by passing in a mark
created with ``new\_mark'', which is the third parameter to replace.

Once the function is defined it is necessary to declare it as a macro
using one of ``make\_syntax\_macro'' or ``make\_macro''.  The first creates a
syntax macro while the second creates a function call macro. (FIXME:
Explain the difference) The first parameter is the name of the macro.
The second is the name of the function to use, if different.

% FIXME: What about id macros.

To understand better how macros work let's look at a simple example.
The macro:

\begin{code}
Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (v, z), syn);
  Syntax * res = replace(syntax {int x = v + y; z = x * x;}, m, mark);
  return res;
}
make_macro foo;
\end{code}

will transform:
\begin{code}
foo(i,j)
\end{code}
to
\begin{code}
int x' = i + j;
j = x' * x';
\end{code}
where the \verb/'/ is a mark on x to keep it from clashing with local variables.

In addition to full macros ZL also supports simple pattern matching.
For example foo can more simply be written as:

\begin{code}
macro foo (v,z) {
  int x = v + y; 
  z = x * x;
}
\end{code}

Pattern matching macros can in fact be defined as a macro in terms of
the above API:

\begin{code}
Syntax * macro(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (name, parms, repl), syn);
  Syntax * res = replace(syntax {
      Syntax * name(Syntax * syn, Environ * env) {
        Mark * mark = new_mark();
        Match * m = match_args(0, syntax parms, syn);
        Syntax * res = replace(syntax repl, m, mark);
        return res;
      }
      make_macro name;
    }, m, mark);
}

make_syntax_macro macro;
\end{code}

However, for efficiency reasons they are defined directly.

\section{The Basic Macro Expansion Algorithm}

This section will describe the basic macro expansion algorithm without
the reparsing steps.  It will primarily focus on the hygiene system.
For simplicity it will be assumed that Smacro parameters and syntax
forms are fully parsed.  The next section will explain the details of
how parsing of both is really done.  

In order to understand how hygiene is maintained it is necessary
understand a little about how programs are parsed.  During parsing an
environment is maintained as a list which is a mapping of symbol names
to symbol objects.  Every symbol name, in both syntax objects and in
the environment, has a set of marks associated with it.  Marks are
used to keep track of where a symbol came from.

The initial environment is empty, when a binding form is encountered
the form is added to the front of a list.  Functions create a new
environment whose tail is the current environment from the top level.
The environment is then populated with the function parameters.
Blocks create their own local environment whose tail is the current
environment where the block was defined.  Macro also capture the
environment using the \verb/new_mark/ primitive.

For example in the code:

\begin{code}
int x = 10;
Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark()
  ...
}
\end{code}

The mark \verb/m/ will contain \verb/x/ in the environment.

Marks are applied to symbols during the replacement process.  During
this process, each symbol is either replaced, if it is a macro
parameter, or marked.  The mark has an environment associated with it
which is simply the environment captured when the macro was defined.

For example the code:

\begin{code}
int x = 10;
Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (y), syn);
  Syntax * res = replace(syntax (x * y), m, mark);
}
make_macro foo;
int main() {
  int x = 20;
  return foo(x);
}
\end{code}

will expand to something like\footnote{Macro expansion really in the
  intermediate s-expression language, but for simplicity the expanded
  results will be presented in the input language in this section.}

\begin{code}
int $x0 = 10;
int main() {
  int $x1 = 20;
  [x => $x1, x => $x0]
  return x'0 * x;
}
'0 := [x => $x0]
\end{code}

Where variables starting with \verb/$/ represent a bound symbol.  The
\verb/[...]/ represents the current environment which maps symbol
names to bound symbols.  The \verb/'0/ is a mark, and the
\verb/'0 := [...]/ is the environment for the mark.

When looking up a binding the current environment is first checked.  If
a symbol with the same set of marks is not found in the current
environment than the outermost mark is stripped and the symbol is
looked up in the environment associated with the mark stripped.  This
process continues until no more marks are left.

For example, in the above example "x'0" will bind to "\$x0", and "x"
will bind to "\$x1".

%% In the \verb/replace/ function
%% each symbol is either replaced if it is a macro parameter
%% or marked.  For example:

%% The mark has an environment associated with it which is
%% simply the environment captured when the macro was defined.  For
%% example given:

%% \begin{code}

%%     (var x 10)
%%     (map foo (y) (+ x y)))
%% \end{code}

%% (foo x) will be expanded to:

%% \begin{code}
%%   (+'0 x'0 x)
%%   '0 := [x => 10]
%% \end{code}

%% Where [x => 10] is the environment associated with the mark.  For
%% simplicity we will assume that variables are constant and the symbol
%% object is simply the associated value.

%% Each expansion of a macro gets a fresh set of marks for example,
%% "(+ (foo x) (foo y))" will expand to:

%% \begin{code}
%%   (+ (+'0 x'0 x) (+'1 x'1 y))
%%   '0 := [x => 10]
%%   '1 := [x => 10]
%% \end{code}

%% If a symbol has marks associated with it in a binding form those marks
%% are preserved in the environment.

%% When looking up a binding the current environment is first checked.  If
%% a symbol with the same set of marks is not found in the current
%% environment than the outermost mark is stripped and the symbol is
%% looked up in the environment associated with the mark stripped.  This
%% process continues until no more marks are left.  If the symbol is
%% still not found then it is assumed to be associated with a primitive
%% form, otherwise it's an error.

%% For example in the above example "(+'0 x'0 x)", "+'0" will bind to the
%% the "+" primitive, while the "x'0" will bind to "10".

\subsection{An Illustrative Example}

We will expand and evaluate the following code:

\begin{code}
int y = 2;

Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (y,z), syn);
  Syntax * res = replace(syntax {int x = x + y;
                                 int v = x + z;}, m, mark);
  return res;
}
make_macro foo;

int main() {
  int y = 4;
  foo(z,y);
  return z;
}
\end{code}
%% map foo(y,z) {
%%  int x = x + y;
%%  int v = x + z;
%% }

When the first binding form, "int y = 2", is parsed ``y'' in bound to
unique symbol ``\$y0'' and the mapping "y => \$y2" is added to the
current environment.  Then when the function "foo" in parsed, it is
added to the environment.  When the \verb/new_mark()/ primitive is
parsed inside the body of the function the current global environment
is remembered.  new\_mark does not capture local variables since it
makes little sense to use them in the result of the macro.  Next,
\verb/macro foo/ is parsed which makes the function foo into a macro.

Now the body of main is parsed.  A new local environment is created.
\verb/int y = 4/ created a new unique symbol ``\$y1'' and the mapping
"y => \$y1" is added.  At this point we have.

\begin{code}
int $y0 = 2;
[foo => ..., y => $y0]
int main () {
  int $y1 = 4;
  [y => $y1, foo => ..., y => $y0]
  foo(z,y);
  return z;
}
\end{code}

where \verb/[...]/ represents the current scope.  Since the local
environment inside the block includes the environment from the outer
scope, y is listed twice since the local y shadows the top level y,
however this is not a problem since lookup started from the head of
the list.

Now foo is expanded and we have:

\begin{code}
  ...
  [y => $y1, foo => ..., y => $y0]
  int z'0 = y + y'0;
  int z = y + z'0;
  return z;
  '0 => [y => $y0]
\end{code}

The marks keep the duplicate y and z's distinct.

Now the statement \verb/int z'0 = y + y'0/ is evaluated.  First off,
\verb/int z'0/ creates a unique symbol ``\$z0'' and the mapping, ``z'0
=> \$z0'' is added to the local environment.  Notice how the mark
becomes part of the name.  Next, the expression \verb/y + y'0/ is
expanded.  The first y binds to ``\$y1'' since it has no marks.  The
second y is not in the local environment since it has a mark
associated with it, so the mark is stripped and the stripped symbol is
looked up in the environment for the mark, thus ``y'0'' binds to
``\$y0''.  We now have:

\begin{code}
  ...
  int $z0 = $y1 + $y0;
  [z'0 => $z0, y => $y1, foo => ..., y => $y0]
  int z = y + z'0;
  return z;
  '0 => [y => $y0]
\end{code}

Now the statement \verb/int z = y + z'0/ is evaluated.  The variable
``z'0'' is found in the local environment since it has the same
set of marks as the one in the local environment and we have:

\begin{code}
  ...
  int $z1 = $y1 + $z0;
  [z => $z1, z'0 => $z0, y => $y1, foo => ..., y => $y0]
  return z;
  '0 => [y => $y0]
\end{code}

And finally the ``z'' in the return statement will bind to ``\$z1'' giving:
\begin{code}
int $y0 = 2;
int main() {
  int $y1 = 4;
  int $z0 = $y1 + $y0;
  int $z1 = $y1 + $z0;
  return $z1;    
}
\end{code}

which will evaluate to

\begin{code}
int $y0 = 2;
int main() {
  int $y1 = 4;
  int $z0 = 4 + 2 = 6;
  int $z1 = 4 + 6 = 10;
  return 10;    
}
\end{code}

and thus main will return 10;

\section{The Reparser}

The previous section glossed over how macros are parsed and the fact
that the expansion happens on the intermediate syntax objects.  This
section will fill in the gaps and explain what is really going on.

When ZL encounters something that looks like a function call, for
example \verb/f(x + 2, y)/ it does not know if it is a true function
or a macro.  If it is a macro the arguments could be an expression, a
statement, or something else entirely depending on the context in
which they are used.  Thus function call arguments are only minimally
parsed in order to separate them from each other.  For example the
function call of \verb/f/ above will get parsed as
\verb/(call (id f) (list (parm "x + 2") (parm y)))/.  After which the
expander looks up the symbol \verb/f/. If it is a macro than it is
expanded with the parsing of the parameters delayed, otherwise it is
assumed to be a function and the parameters will get parsed as an
expression as the function is parsed.

In addition, as previously mentioned, syntax forms such as
\verb/syntax (x * y)/ are not fully parsed but rather in this case
first becomes \verb/("()" "x * y")/.  This is because it is not known
if x and y are local variables or pattern variables until the
substitution is performed.  If they are normal variables then it
will be parsed as \verb/(exp (id x) (syn *) (id y))/ but if they were
pattern variables it will be parsed as
\verb/(exp (mid x) (syn *) (mid y))/, where ``mid'' is a macro
identifier.

Even when a substitution is performed using the \verb/replace/ callback
function, the syntax object is not parsed.  This is for two reasons: 1)
we still do not know what context the results are going to be used in,
thus we cannot be completely sure what it should be
parsed as, and 2) by delaying the substitution until it is needed we
can reduce the complexity of the macro expansion from quadratic to
linear.  Instead a list of substitutions is stored with the syntax
object which will be used when the syntax object is finally parsed.

For example in the code:

\begin{code}
int x = 10;
Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (y), syn);
  Syntax * res = replace(syntax (x * y), m, mark);
}
make_macro foo;
int main() {
  int x = 20;
  return foo(x);
}
\end{code}

the call \verb/foo(x)/ will first get parsed as
\verb/(call (id foo) (list (parm x)))/.  When the symbol foo is looked
up ZL discoverers it is a macro and then calls the function foo to
expand it.  Foo first creates a new mark which will be used latter.
Next match\_args is called which will map y to \verb/(parm x)/.  Then
replace is called.  First the \verb/syntax (x * y)/ is parsed as
\verb/("()" "x * y")/. Next replace will annotate it with two bits
or information 1) the mark to apply, and 2) the substitutions to apply.
This will be represented as \verb/{'0; y => (parm x)}/
where the first part is the mark and the second is the substitutions to
apply.  Thus after the expansion the above code will become:

\begin{code}
(top
  (var (id $x0) int 10)
  (fun (id main) () (block
    (var (id $x1) int (literal 20))
    [x => $x1, x => $x0]
    (return ("()" "x * y"){'0; y => (parm x)})))
'0 := [x => $x0]
\end{code}

The result of the macro will get parsed when return is converted from a
syntax object to an AST node.  In the process of doing this it will
partly expand its parameter.  The expander will recognize the \verb/()/
as something that needs to be reparsed and instruct the reparser to reparse
\verb/x * y/ as an ``EXP'' and then apply \verb/{'0; y => (parm x)}/.

The reparser will first use the PEG parser to reparse the string 
as an EXP with the special instruction that \verb/y/ is
an macro parameter.  This will then get parsed as
\verb/(exp (id x) (sym +) (mid y PARM))/.  The parser is able to recognize y
as a ``mid'' rather than an ``id'' because of the special \verb/MID/
production in the grammar:

\begin{code}[fontsize=\small]
...
EXP = <exp> {TOKEN}+;
TOKEN : "token" = 
      <<mid PARM>> {MID} / {BRACK} / {CONST} / 
      <id> {ID} / <sym> {SYM} / PARAN;
...
MID : "macro identifier" = 
     {[@$\a_][\a_\d]*} SPACING;
PARM : "macro paramater" = 
   {STMT} EOF / {TOKEN} EOF / {EXP} EOF;
\end{code}

That is when trying to match a token the MID production is tried, it
matches ``x'' but it is rejected because the special instruction
\verb/<<mid>>/ tells the PEG parser to reject the match unless the
string is in the list of possible macro identifiers.  However, when it
matches ``y'' it is accepted since ``y'' is in the list.  When a MID
matched the parser adds a note as to how to reparse the macro
parameter.  This is either the production where it matches, or the
production as given in the \verb/<<mid>>/ instruction.  In this case
it is the ``PARM'' production.

After the string is parsed it will then apply the
\verb/{'0; y => (parm x)}/ instructions to the sub-parts.  This will
result in \verb/(exp'0 (id'0 x'0) (syn +) (id x))/.  That is marks are
applied to most of the symbols while \verb/(mid y PARM)/ becomes
\verb/(id x)/.  During the substitution the string, \verb/x/, is
reparsed as the production noted in the second argument of the
\verb/mid/, which in this case in ``PARM''.  Hence, \verb/x/ becomes
\verb/(id x)/.  \verb/(syn +)/ does not get a symbol because ``sym''
is a special case of a syntax form which does not get additional
processing; other forms include literal numbers, and strings.

The results of the reparse are then expanded and parsed as before,
with marks being used as described in the previous section, with the
additional rule that if no marks are left and a symbol is still not
found than it is assumed to be associated with a primitive form.  For
example ``exp'0'' and ``id'0'' will be assumed to represent the built
in ``exp'' macro and the ``id'' primitive since neither are in the
current environment.  Since the result is an ``exp'' it will be
expanded again to become \verb/(plus (id'0 x'0) (id x))/, 
which will than be converted into an AST.

In this case the result of the reparse is a fully parsed string, but
this is not always the case, for example if the macro instead expanded
to \verb/("()" "(x + 2) * y")/ the string will parse to
\verb/(exp ("()" "x + 2") (sym *) (mid y))/ and then become
\verb/(exp'0 ("()" "x + 2"){'0; y => (parm x)} (sym *) (id x))/, that
is if any unparsed string are encountered the instructions are simply
pushed down rather than being directly applied.

In the above example the macro parameter was just an identifier and the
special ``PARM'' production is not needed as it would of correctly
parsed as a ``TOKEN''.  However this is not always the case, for
example if the call to foo was instead \verb/foo(x + 2)/, as the
string \verb/x + 2/ is not a token.

The reparsing of the macro parameters is only applied to function call
macros.  For syntax macros the parameters are already
parsed\footnote{Well partly...}.  This is possible because the
production the parameter should be parsed as is known... FIXME: Need
better explanation of syntax macros earlier in text.

As the lazy substation of macro parameters and the reparsing are
intertwined, lazy substitution only applies to syntax forms that are to
be reparsed, for example ``()'' and ``\{\}'' forms.  Syntax created
with the \verb/syntax/ form is always of the form to be reparsed,
however syntax created with \verb/raw_syntax/ is fully parsed and thus
replace performs the substitutions eagerly.

ALSO EXPLAIN HOW MULTIPLE REPLACEMENT SETS ARE HANDLED.

\section{Bending Lexical Scope}

Normal hygiene rules for macros work well in most cases, but it is
often necessary to bend lexical scope.  For example ... CLASS EXAMPLE.

ZL produces two different mechanisms to support this....

\subsection{Get\_context and Replace\_context}
\label{replace_context}

The first is get\_context and replace\_context.  It is used when there
is a need to create new symbols as if they are in the context of an
existing symbol.  Get\_context and replace\_context are callback
functions with the following prototype:
\begin{itemize*}
\item \verb/Context * get_context(Syntax *)/
\item \verb/Syntax * replace_context(UnmarkedSyntax *, Context *)/
\end{itemize*}
A ``Context'' is simply a collection of marks.  Thus get\_context
simply gets the marks associated with the Syntax object, while
replace\_context replaces the marks of a syntax object.  If an syntax
object already has any marks associated with it, they are ignored.

\subsection{Fluid Binding}

\subsubsection{The Idea}

get\_context and replace\_context is not always the correct solution.
Sometimes what is needed is a form of dynamic binding...  A prime
example of this is the special variable ``this'' in classes.  For this
ZL provides a new construct ``fluid\_binding''... JUSTIFY ...

Variables in ZL are lexically scoped, for example the code:

\begin{code}
int g(X *);
int f() {return g(this);}
int main() {X * this = ...; return f();}
\end{code}

will not compile because the ``this'' defined in main() is not visible in
f() even, though f() is called inside main().  However, if variables
where instead dynamically scoped the ``this'' in main() will be visible
to f().  

Normal hygiene rules preserve lexical scope in a similar fashion such that:

\begin{code}
int g(X *);
map m() {g(this);}
int main() {X * this = ...; return m();}
\end{code}

will also not compile.  Attempts to make this work with get and
replace context will not compose well.  FIXME: Give example. What is
really needed is for this to be dynamically scoped in the hygiene
system.  This can be done by marking the ``this'' symbol as ``fluid''
using ``fluid\_binding'' at the top level and then using ``fluid''
when defined the symbol in local scope.  For example:

\begin{code}
fluid_binding this;
int g(X *);
map m() {g(this);}
int main() {X * fluid this = ...; return m();}
\end{code}

will work as expected.  That is the ``this'' in m() will bind to the
``this'' in main(). 

\subsubsection{The Implementation}

The key idea to making fluid\_binding work is that when a fluid
variable is defined it is renamed to a unique symbol name that is
associated with fluid\_binding.  This has the effect of making uses of
the variable first resolve to the fluid\_binding form instead of the
local variable.  During the resolution process variables that resolve
to a fluid\_binding form, will be looked up again, but this time using
the unique symbol name associated with the fluid\_binding form.  This
will then correctly resolve to the local variable.

As such, the fluid\_binding construct will insert a special symbol into
the environment which contains a unique symbol name constructed by
taking the symbol name and applying a fresh mark to it (with an empty
environment) which will be represented as \verb/fluid(SYMBOL'MARK')/
for example /verb/fluid\_binding this/ will insert the mapping
\verb/this => fluid(this'0)/ into the environment.

The \verb/fluid/ construct will then look up the symbol name in the
environment and replace it with the unique symbol name associated with
the fluid binding.  For example \verb/X * fluid this/ will become
\verb/X * this'0/, which will insert the mapping
\verb/this'0 => $this0/ into the environment.

Finally, when ever a symbol resolves to something that is a fluid
binding the symbol will be resolved again, this time using the unique
symbol name in the fluid binding.  For example ``this'' will first
resolve to ``fluid(this'0)''.  Next, ``this'0'' resolves to
``\$this0''.

\subsubsection{Example}

In the code:

\begin{code}
fluid_binding this;
int g(X *, X *) {...}
map m1(body) {{X * fluid this = ...;body}}
map m2(x) {g(x,this);}
int main() {
  X * this = ...;
  m1(m2(this));
}
\end{code}

Thu fluid binding this is first parsed, and added to the environment
as \verb/this => fluid(this'0)/ where \verb/'0/ is an empty mark.  The
function ``g'' and macros ``m1'' and ``m2'' are also parsed and added
to the environment giving:

\begin{code}
int $g0(X *, X *);
[m2 => ..., m1 => ..., g => $g0, this => fluid(this'0)]
'0 => [];
...
\end{code}

Next main is parsed, first the local variable ``this'' is parsed and
added to the environment.  Since it was not prefixed with ``fluid'',
it is just an ordinarily variable which happens to have the same name as
the global fluid binding ``this'', thus shadowing it.  Now we have:

\begin{code}
int main() {
  X * $this0 = ...
  [this => $this0, m2 => ..., m1 => ..., g => $g0, this => ...]
  m1(m2(this));
}
\end{code}

Next ``m1'' is expanded giving:

\begin{code}
int main() {
  X * this$0 = ...
  [this => $this0, m2 => ..., m1 => ..., g => $g0, this => ...]
  { X * fluid this'1 = ...;
    m2'1(this);}
}
'1 = [m2 => ..., m1 => ..., g => $g0, this => fluid(this'0)]
\end{code}

Now the fluid variable ``this'1'' is parsed.  The symbol is looked up
using the normal strategy and is found to correspond to the symbol
fluid(this'0).  Thus ``fluid this'1'' becomes ``this'0'' and a mapping
\verb/this'0 => \$this1/ is added to the local environment.

\begin{code}
int main() {
  X * $this0 = ...;
  { X * $this1 = ...;
    [this'0 => $this1, this => $this0, m2 => ..., m1 => ..., g => $g0, ...]
    m2'1(this);}
}
\end{code}

Next ``m2'1'' is expanded:

\begin{code}
int main() {
  { ...   
    [this'0 => $this1, this => $this0, m2 => ..., m1 => ..., g => $g0, ...]
    g'2(this, this'2); }
}
'2 = [m2 => ..., m1 => ..., g => $g0, this => fluid(this'0)]
\end{code}

Now ``g'2'' and ``this'' resolve as expected.  And ``this'2'' is
resolved.  When resolving ``this'2'', it first resolves to
fluid(this'0), which is an instruction to try the lookup again, this
time using ``this'0'' as the symbol name.  Thus ``this'0'' is looked
up in the current environment, and resolves to ``\$this0''. Thus,
giving:

\begin{code}
int $g0(X *, X *);
int main() {
  X * $this0 = ...;
  { X * $this1 = ...;
    $g0($this0, $this1);}
}
\end{code}

\section{The Complete Macro ABI}

\subsection{Creating Marks}

The ``new\_mark'' primitive is actually a macro with which calls the
callback function new\_mark\_f and uses the primitive
``environ\_snapshot()'' to capture the environment.  The ABI is thus:

\begin{itemize*}
\item The type \verb/EnvironSnapshot/
\item The type \verb/Mark/
\item \verb/Mark * new_mark_f(EnvironSnapshot *)/
\item \verb/macro new_mark() {new_mark_f(environ_snapshot());}/
\item \verb/macro new_empty_mark() {new_mark_f(0);}/ --
      creates a mark with an empty environment.
\end{itemize*}

\subsection{The Syntax Object}

There are two syntax objects types, \verb/UnmarkedSyntax/ and
\verb/Syntax/.  The difference between the two is the first represents
a syntax object that has not been marked yet, while the second one
has.  A \verb/Syntax/ object automatically convert to
\verb/UnmarkedSyntax/.  But in order to go from \verb/UnmarkedSyntax/
to \verb/Syntax/ the syntax object needs be marked, which is generally
done via \verb/replace/.

FIXME: Explain flags.

\subsection{The Syntax List}

...

\subsection{Matching}

...

\subsection{Replace}

...

\subsection{Get and Replace Context}

As described in section \ref{replace_context}.

\subsection{Expanding and Reparsing}

...

\subsection{Converting Between Identifers to Strings}

\begin{itemize*}
\item \verb/UnmarkedSyntax * string_to_syntax(const char *)/
\item \verb/const char * syntax_to_string(UnmarkedSyntax *)/
\end{itemize*}

\end{document}


%% ----

%% parse_str(String how, String what) : Syntax
%%   Parses the string "what" with production "how" and returnes a syntax
%%   object representing the parsed string.  Does not expand.

%% parse_top(Syntax, Environ) : void
%%   Parses the top level.  Does not return a value, instead populates
%%   environment with the top level declarations.

%% main = parse_top(parse_str("TOP", <source file>))

%% ---



