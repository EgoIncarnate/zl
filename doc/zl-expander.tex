%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt,english,letterpaper]{article}
\usepackage{pslatex}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
%\usepackage{geometry}
%\geometry{letterpaper,dvips,
%          top=1in,
%          bottom=1in,
%          left=1.5in,
%          right=1.5in}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{mdwlist}

% Note: when changing spacing also change to code macro below
%\singlespacing
\onehalfspacing
%\doublespacing
\setlength\parskip{\bigskipamount}
\setlength\parindent{0pt}

\IfFileExists{url.sty}{\usepackage{url}}
                      {\newcommand{\url}{\texttt}}
\usepackage{hyperref}

\special{papersize=8.5in,11in}
\pdfpageheight\paperheight
\pdfpagewidth\paperwidth

\makeatletter
\usepackage{babel}
\makeatother

\DefineVerbatimEnvironment
  {code}{Verbatim}{baselinestretch=1,xleftmargin=2ex}

\newcommand{\subs}[1]{$_{#1}$}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{The ZL Parser and Macro Expander}
\author{Kevin Atkinson}

\section{Overview}

Parsing a source file in ZL is a three step process.  In the first
step a string of characters in converted to a syntax object, in other
words a string is parsed into a syntax object.  The grammar is
specified as a PEG and a Packrat parser is used to convert the string of
characters to a syntax object.  The second step is the expander, in
this step syntax objects are manipulated into other syntax objects.
It is here where macros are expanded.  Finally, in the third step
syntax objects are converted in an AST.  However, these three steps
are deeply intertwined.

The process starts by performing an initial parse of the source code
into a syntax object using the Packrat parser.  This initial parse
serves to separate the source code in separate declarations.  It does
not fully parse the code, in particular anything between grouping
characters "()", "\{\}", and "[]" is only minimally parsed to match
grouping characters and returned as an unparsed string.

The syntax object returned after this is essentially a list of
declarations.  Each declaration is converted into an AST object and
added to the environment.  In order to do this it is necessary to partly
expand the syntax object to expand any macros and perform any other
necessary transformations.  The partial expansion will expand just
enough to expose the top level form so we know what type of AST object
it needs to be converted to.

Once the top level form is exposed, it is converted into an AST
object.  During the conversion each of its parts is also converted to
an AST.  This conversion thus involves partly expanding the source
code.  Thus as a syntax object is converted into an AST it is expanded
as necessary, which means at no point during the expansion process is
a completely expanded syntax object available.

\section{The Initial Parse \& Top Level Grammar}

The expansion/parsing process starts out by performing an initial
parse of the source code into a syntax object using the Packrat parser
using something like\footnote{For the complete grammar see ...} the
following grammar:

\begin{code}[fontsize=\small]
TOP = <top> SPACING {STMT}+;

STMT : "statement" = 
      <<mid>> {MID} ";"
    / <if>    "if" "(" {EXP} ")" {STMT} ("else" {STMT})?
    / <while> "while" "(" {EXP} ")" {STMT}
    / <break>    "break" ";"
    / <continue> "continue" ";"
    / <return>   "return" {EXP} ";"
    # other statements ...
    / <stmt>   ({TOKEN_}+ {PARAN} {BRACE} / {TOKEN}+ ";")
   ;

EXP = <exp> {TOKEN}+;

TOKEN_ : "token_" =  
      <<mid>> {MID} / {BRACK} / {CONST} / <id> {ID} / <sym> {SYM};
TOKEN : "token" = TOKEN_ / PARAN;

PARAN = <()> "(" {RAW_TOKEN*} ")";
BRACE = <{}> "{" {RAW_TOKEN*} "}";
BRACK = <[]> "[" {RAW_TOKEN*} "]";

CONST = <float> ...  / <literal> ... / <string> ... / <char> ...

ID : "identifier" =
  <<mid>> {MID} / {[@$\a_][\a_\d]*} SPACING;

SYM : "symbol" = {'...' / '==' / '+' / ...} SPACING;

RAW_TOKEN = STRING / CHAR / BRACE / PARAN / BRACK / COMMENT / [^\)\]\}];

STRING = '"' ('\\'_/[^"])+ '"' SPACING;
CHAR   = '\'' ('\\'_/[^'])+ '\'' SPACING;

SPACING : "spacing" = [\s]* COMMENT?;

COMMENT = ...;
\end{code}

In this grammar specification the standard Packrat operators are
supported.  That is, given any existing parsing expressions e, e1, and
e2, a new parsing expression can be constructed using the following
operators:
\begin{itemize*}
\item Grouping: (e)
\item Literal string: ' '
\item Literal string: " "
\item Character class: [ ]
\item Any character: \_
\item Optional: e?
\item Zero-or-more: e*
\item One-or-more: e+
\item And-predicate: \&e
\item Not-predicate: !e
\item Sequence: e1 e2
\item Ordered choice: e1 / e2
\end{itemize*}
as well as some additional operators for constructing syntax objects:
\begin{itemize*}
\item Capture: {e}
\item Named Capture: <> e
\end{itemize*}

The capture operators are used for constructing syntax objects in the
obvious ways.  The special \verb/<<mid>>/ operator and \verb/MID/
production will be explained latter.

The grammar serves to separate individual statements and declarations
and to recognize forms which are convenient to do using a Packrat
parser.  As noted earlier, it does not fully parse the code.  In
particular anything between grouping characters "()", "\{\}", and "[]"
is only minimally parsed to match grouping characters and returned as
an unparsed string.  In addition declarations and expressions are not
parsed at this point, and are represented as a list of tokens.

For example the program:

\begin{code}
int x = 20;

int main() {
  x = x + 5;
  return x;
}
\end{code}

will become

\begin{code}
(top 
  (stmt (id int) (id x) (sym =) (literal 5))
  (stmt (id int) (id main) ("()") ("{}" "x = x + 5; return x;")))
\end{code}

Next the individual statements are converted to an AST, partly
expanding as necessary.

\section{The Conversion to an AST \& The Partial Expander}

After the initial parse each statement is converted into an AST object
and added to the environment.  In order to do this it is necessary to
partly expand the syntax object to expand any macros and perform any
other necessary transformations.  The partial expansion will expand just
enough to expose the top level form so we know what type of AST object
it needs to be converted to.

In addition to normal macros the partial expander handles several
special forms which could be considered macros since it converts
from one syntax object to another.  These forms are ``stmt'', ``exp'',
``()'', ``[]'', and ``\{\}''.

The ``stmt'' macro recognizes declarations and expressions.  First the
declarations expander is tried and if that fails the expression
expander is tried.  These are necessary because the current PEG
grammar does not necessarily return a valid top-level form.  It will
only recognize block structures such as "if" and "while" forms.  It
will not recognize functions, variable declarations and expressions.
The reason for this is primarily pragmatic.  Correctly parsing C and
C++ declarations involves maintaining state.  This is inherently
incompatible with Packrat parsing while grammar for expressions
generally involves left-recursion, again incompatible with Packrat
parsing.  With work both of these problems can be addressed in the
Packrat parser.  It is possible to have limited state....  It is also
fairly straightforward to convert a grammar with left-recursion to one
that is not....  In addition it is even possible to modify the Packrat
parser to support left recursion...  Nevertheless, I chose to avoid
these two issues completely by using a PEG grammar which essentially
parses a statement into a list of tokens if it not a not a recognized
block structure.  I use the term "tokens" loosely here, since anything
inside of a ``()'', ``\{\}'', or ``[]'' is treated as one token.  As
with everything else both these expander do not fully expand the
``stmt''.  For example the statement:
\begin{code}
x = (x + 1) * 2;
\end{code}
will first get parsed as:
\begin{code}
(stmt (id x) (sym =) ("()" "x + 1") (sym *) (literal 2))
\end{code}
which will become:
\begin{code}
(assign (id x) (times ("()" "x + 1") (literal 2)))
\end{code}
with the \verb/(x + 1)/ left unparsed.

The ``exp'' macro is like the ``stmt'' macro but only the expression
expander is tried.

The other two macros ``()'', ``[]'', and ``\{\}'' macros are used for
reparsing strings.  The ``()'' and ``[]'' macros reparses the string
as an expression using the ``EXP'' production in the grammar, while
the ``\{\}'' reparses the string as a list of statements using the
``SLIST'' production which is as follows:
\begin{code}
SLIST = <@> SPACING {STMT}+;
\end{code}
The ``@'' means ``list of'' which becomes a list of AST nodes. 

If the syntax object is not one of the previously mentioned special
forms than normal macro expansion is tried.  Macros can be in one of
three forms. 1) Syntax macros which can be considered new syntax
forms.  These forms generally come from new PEG productions but can
also be the results of other macros.  Syntax macros are of the form
\verb/(XXX ...)/ where \verb/XXX/ is the macro name.  2) Function call
macros which have the form \verb/(call XXX ("()" "..."))/, and 3)
Identifier macros which have the form \verb/(id XXX)/.  No matter form
the macro is in, the mechanism of expansion is the same, which will be
described in the next section.

If any expansion is done the process is repeated on the result of the
expansion.  If there is no expansion the syntax object is assumed to
represent a primitive and is converted into an AST node or list of AST
nodes in the case of a ``@''.  During the conversion to an AST node
the individual parts will be partly expanded as necessary, thus
repeating the process and eventually fully expanding the source code.
However, the end result is a AST tree and not a fully expanded syntax
object.

\section{Macros}

A macro is a normal function which takes in syntax object and an
environment, and returns a transformed syntax object.  It transforms the
syntax object via call back functions.  The core Macro API consists of:
\begin{itemize*}
\item the types:
\begin{itemize*}
\item UnmarkedSyntax
\item Syntax
\item Match
\item Mark
\end{itemize*}
\item the call back functions:
\begin{itemize*}
\item \verb/Match * match_args(Match *, UnmarkedSyntax * pattern, Syntax * with)/
\item \verb/Syntax * replace(UnmarkedSyntax *, Match *, Mark *)/
\end{itemize*}
\item and syntax forms:
\begin{itemize*}
\item \verb/new_mark()/ -- returns \verb/Mark */
\item \verb/syntax (...)|{...}|ID/ -- returns \verb/UnmarkedSyntax */
\item \verb/raw_syntax (...)/ -- returns \verb/UnmarkedSyntax */
\item \verb/syntax_macro [ID] [ID];/
\item \verb/macro ID [ID];/
\end{itemize*}
\end{itemize*}

One of the most important part of a macro is the ability to create new
syntax, this is done using the \verb/syntax/ and \verb/raw_syntax/
primitive.  Exactly what type of syntax object is created depends on
which form is used, for the \verb/syntax/ forms, it is as follows:
\begin{description}
\item[\texttt{syntax (...)}] a ``()'', which generally parsed as an expression
\item[\texttt{syntax \{...\}}] a ``\{\}'', which is generally parsed as an statement block
\item[\texttt{syntax ID}] an identifier
\end{description}
The \verb/raw_syntax/ directly creates a syntax object without any
additional reparsing.  That is
\verb/raw_syntax (times (id x) (literal 2))/ creates exactly that,
which is almost the same as \verb/syntax (x * 2)/ but it first gets
parsed as \verb/("()" "x * 2")/ and than latter gets transformed to
\verb/(times (id x) (literal 2)/.

Creating syntax alone is not very useful without being able to perform
substitution on pattern variables.  This is what the ``match'' and
``replace'' function is for.  The ``match'' function is used to
decompose the input by matching pattern variables, the second
parameter, with the arguments of the macro, the third
parameter.  (The first argument, which will be explained latter, is
generally null).  The ``replace'' function is used to rebuild the
output by matching the passed in syntax object, the first parameter
and generally created with ``syntax'', with the pattern variables
in the ``Match'' object, the second parameter.  However, syntax
objects created with ``syntax'', do not have any lexical information
associated with them, in other words they are unmarked.  Thus it is
necessary to attach lexical information to them by passing in a mark
created with ``new\_mark'', which is the third parameter to replace.

Once the function is defined it is necessary to declare it as a macro
using one of ``syntax\_macro'' or ``macro''.  The first creates a
syntax macro while the second creates a function call macro. (FIXME:
Explain the difference) The first parameter is the name of the macro.
The second is the name of the function to use, if different.

% FIXME: What about id macros.

To understand better how macros work lets look at a simple example.
The macro:

\begin{code}
Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (v, z), syn);
  Syntax * res = replace(syntax {int x = v + y; z = x * x;}, m, mark);
  return res;
}
\end{code}
macro foo;

will transform:
\begin{code}
foo(i,j)
\end{code}
to
\begin{code}
int x' = i + j;
j = x' * x';
\end{code}
where the \verb/'/ is a mark on x to keep it from clashing with local variables.

In addition to full macros. ZL also supports simple pattern matching
for example foo can more simply be written as:

\begin{code}
map foo (v,z) {
  int x = v + y; 
  z = x * x;
}
\end{code}

Pattern matching macros can in fact be defined as a macro in terms of
the above API:

\begin{code}
Syntax * map(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (name, parms, repl), syn);
  Syntax * res = replace(syntax {
      Syntax * name(Syntax * syn, Environ * env) {
        Mark * mark = new_mark();
        Match * m = match_args(0, syntax parms, syn);
        Syntax * res = replace(syntax repl, m, mark);
        return res;
      }
      macro name;
    }, m, mark);
}

syntax_macro map;
\end{code}

However, for efficiency reasons they are defined directly.

\section{The Basic Macro Expansion Algorithm}

This section will describe the basic macro expansion algorithm without
the reparsing steps.  It will primary focus on the hygiene system.
For simplicity it will be assumed that macro parameters and syntax
forms are fully parsed.  The next section will explain the details of
how parsing of both is really done.  

In order to understand how hygiene is maintained it is necessary
understand a little of how programs are parsed.  During parsing an
environment is maintained as a list which is a mapping of symbol names
to symbol objects.  Every symbol name, in both syntax objects and in
the environment, has a set of marks associated with it.  Marks are
used to keep track of where a symbol came from.

The initial environment is empty, when a binding form is encountered
the form is added to the front of a list.  Functions create a new
environment whose tail is the current environment from the top level.
The environment is then populated with the function parameters.
Blocks create they own local environment whose tail is the current
environment where the block was defined.  Macro also capture the
environment using the \verb/new_mark/ primitive.

For example in the code:

\begin{code}
int x = 10;
Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark()
  ...
}
\end{code}

The mark \verb/m/ will contain \verb/x/ in the environment.

Marks are applied to symbols during the replacement process.  During
this process, each symbol is either replaced, if it is a macro
parameter, or marked.  The mark has an environment associated with it
which is simply the environment captured when the macro was defined.

For example the code:

\begin{code}
int x = 10;
Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (y), syn);
  Syntax * res = replace(syntax (x * y), m, mark);
}
macro foo;
int main() {
  int x = 20;
  return foo(x);
}
\end{code}

will expand to something like\footnote{Macro expansion really in the
  interment s-expression language, but for simplicity the expanded
  results will be presented in the input language in this section.}

\begin{code}
int $x0 = 10;
int main() {
  int $x1 = 20;
  [x => $x1, x => $x0]
  return x'0 * x;
}
'0 := [x => $x0]
\end{code}

Where variables starting with \verb/$/ represent a bound symbol.  The
\verb/[...]/ represents the current environment which maps symbol
names to bound symbols.  The \verb/'0/ is a mark, and the
\verb/'0 := [...]/ is the environment for the mark.

When looking up a binding the current environment is first checked.  If
a symbol with the same set of marks is not found in the current
environment than the outermost mark is stripped and the symbol is
looked up in the environment associated with the mark stripped.  This
process continues until no more marks are left.

For example, in the above example "x'0" will bind to "\$x0", and "x"
will bind to "\$x1".

%% In the \verb/replace/ function
%% each symbol is either replaced if it is a macro parameter
%% or marked.  For example:

%% The mark has an environment associated with it which is
%% simply the environment captured when the macro was defined.  For
%% example given:

%% \begin{code}

%%     (var x 10)
%%     (map foo (y) (+ x y)))
%% \end{code}

%% (foo x) will be expanded to:

%% \begin{code}
%%   (+'0 x'0 x)
%%   '0 := [x => 10]
%% \end{code}

%% Where [x => 10] is the environment associated with the mark.  For
%% simplicity we will assume that variables are constant and the symbol
%% object is simply the associated value.

%% Each expansion of a macro gets a fresh set of marks for example,
%% "(+ (foo x) (foo y))" will expand to:

%% \begin{code}
%%   (+ (+'0 x'0 x) (+'1 x'1 y))
%%   '0 := [x => 10]
%%   '1 := [x => 10]
%% \end{code}

%% If a symbol has marks associated with it in a binding form those marks
%% are preserved in the environment.

%% When looking up a binding the current environment is first checked.  If
%% a symbol with the same set of marks is not found in the current
%% environment than the outermost mark is stripped and the symbol is
%% looked up in the environment associated with the mark stripped.  This
%% process continues until no more marks are left.  If the symbol is
%% still not found then it is assumed to be associated with a primitive
%% form, otherwise it's an error.

%% For example in the above example "(+'0 x'0 x)", "+'0" will bind to the
%% the "+" primitive, while the "x'0" will bind to "10".

\subsection{An Illustrative Example}

We will expand and evaluate the following code:

\begin{code}
int y = 2;

Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (y,z), syn);
  Syntax * res = replace(syntax {int x = x + y;
                                 int v = x + z;}, m, mark);
  return res;
}
macro foo;

int main() {
  int y = 4;
  foo(z,y);
  return z;
}
\end{code}
%% map foo(y,z) {
%%  int x = x + y;
%%  int v = x + z;
%% }

When the first binding form, "int y = 2", is parsed ``y'' in bound to
unique symbol ``\$y0'' and the mapping "y => \$y2" is added to the
current environment.  Then when the function "foo" in parsed, it is
added to the environment.  When the \verb/new_mark()/ primitive is
parsed inside the body of the function the current global environment
is remembered.  new\_mark does not capture local variables since it
makes little sense to use them in the result of the macro.  Next,
\verb/macro foo/ is parsed which makes the function foo into a macro.

Now the body of main is parsed.  A new local environment is created.
\verb/int y = 4/ created a new unique symbol ``\$y1'' and the mapping
"y => \$y1" is added.  At this point we have.

\begin{code}
int $y0 = 2;
[foo => ..., y => $y0]
int main () {
  int $y1 = 4;
  [y => $y1, foo => ..., y => $y0]
  foo(z,y);
  return z;
}
\end{code}

where \verb/[...]/ represents the current scope.  Since the local
environment inside the block includes the environment from the outer
scope, y is listed twice since the local y shadows the top level y,
however this is not a problem since lookup started from the head of
the list.

Now foo is expanded and we have:

\begin{code}
  ...
  [y => $y1, foo => ..., y => $y0]
  int z'0 = y + y'0;
  int z = y + z'0;
  return z;
  '0 => [y => $y0]
\end{code}

The marks keep the duplicate y and z's distinct.

Now the statement \verb/int z'0 = y + y'0/ is evaluated.  First off,
\verb/int z'0/ creates a unique symbol ``\$z0'' and the mapping, ``z'0
=> \$z0'' is added to the local environment.  Notice how the mark
becomes part of the name.  Next, the expression \verb/y + y'0/ is
expanded.  The first y binds to ``\$y1'' since it has no marks.  The
second y is not in the local environment since it has a mark
associated with it, so the mark is stripped and the stripped symbol is
looked up in the environment for the mark, thus ``y'0'' binds to
``\$y0''.  We now have:

\begin{code}
  ...
  int $z0 = $y1 + $y0;
  [z'0 => $z0, y => $y1, foo => ..., y => $y0]
  int z = y + z'0;
  return z;
  '0 => [y => $y0]
\end{code}

Now the statement \verb/int z = y + z'0/ is evaluated.  The variable
``z'0'' is found in the local environment since it has the same
set of marks as the one in the local environment and we have:

\begin{code}
  ...
  int $z1 = $y1 + $z0;
  [z => $z1, z'0 => $z0, y => $y1, foo => ..., y => $y0]
  return z;
  '0 => [y => $y0]
\end{code}

And finally the ``z'' in the return statement will bind to ``\$z1'' giving:
\begin{code}
int $y0 = 2;
int main() {
  int $y1 = 4;
  int $z0 = $y1 + $y0;
  int $z1 = $y1 + $z0;
  return $z1;    
}
\end{code}

which will evaluate to

\begin{code}
int $y0 = 2;
int main() {
  int $y1 = 4;
  int $z0 = 4 + 2 = 6;
  int $z1 = 4 + 6 = 10;
  return 10;    
}
\end{code}

and thus main will return 10;

%% \section{Macro Expander}

%% [Now describe in detail how each of the Macro expander works,
%%   including the hygiene system].

\section{The Reparser}

The previous section glossed over how macros are parsed and the fact
that the expansion happens on the intermediate syntax objects.  This
section will fill in the gaps and explain what is really going on.

When ZL encounters something that looks like a function call, for
example \verb/f(x + 2, y)/ it does not know if it is a true function
or a macro.  If it is a macro the arguments could be an expression, a
statement, or something else entirely depending on the context in
which they are used.  Thus function call arguments are only minimally
parsed in order to separate them from each other.  For example the
function call of \verb/f/ above will get parsed as
\verb/(call (id f) (list (parm "x + 2") (parm y)))/.  After which the
expander looks up the symbol \verb/f/. If it is a macro than it is
expanded with the parsing of the parameters delayed, otherwise it is
assumed to be a function and the parameters will get parsed as an
expression as the function is parsed.

In addition, as previously mentioned, syntax forms such as
\verb/syntax (x * y)/ are not fully parsed but rather first becomes
\verb/("()" "x * y")/.  This is because it is not known if x and y are
local variables or pattern variables until the substitution is
performed.  If they are normal variables then they it will be parsed as
\verb/(exp (id x) (syn *) (id y))/ but if they where pattern variable it will be
parsed as \verb/(exp (mid x) (syn *) (mid y))/.

Even when substitution is performed using the \verb/replace/ callback
function, the syntax object is not parsed.  This is for two reasons: 1)
we still do not know what context the results are going to be used in,
thus we can not be completely sure what it should be
parsed as and 2) by delaying the substitution until it is needed we
can reduce the complexity of the macro expansion from quadratic to
linear.  Instead a list of substations is stored with the syntax
object which will be used when the syntax object is finally parsed.

For example in the code:

\begin{code}
int x = 10;
Syntax * foo(Syntax * syn, Environ * env) {
  Mark * mark = new_mark();
  Match * m = match_args(0, syntax (y), syn);
  Syntax * res = replace(syntax (x * y), m, mark);
}
macro foo;
int main() {
  int x = 20;
  return foo(x);
}
\end{code}

the call \verb/foo(x)/ will first get parsed as
\verb/(call (id foo) (list (parm x)))/.  When the symbol foo is looked
up ZL discoverers it is a macro and than calls the function foo to
expand it.  Foo first creates a new mark which will be used latter.
Next match\_args is called which will map y to \verb/(parm x)/.  Then
replace is called, first the \verb/syntax (x * y)/ is parsed as
\verb/("()" "x * y")/ and then replace will annotate it with two bits
or information 1) the mark to apply, and 2) the substations to apply.
This will which will be represented as \verb/{'0; y => (parm x)}/
where the first part is the mark and the second is the substations to
apply.  Thus after the expansion the above code will become:

\begin{code}
(top
  (var (id $x0) int 10)
  (fun (id main) () (block
    (var (id $x1) int (literal 20))
    [x => $x1, x => $x0]
    (return ("()" "x * y"){'0; y => (parm x)})))
'0 := [x => $x0]
\end{code}

The result of the macro will get parsed when return is converted from a
syntax object to an AST node.  In the process of doing this it will
partly expand it's parameter.  The expander will recognize the \verb/()/
as something that needs to be reparsed and instruct the reparser to reparse
\verb/x * y/ as an ``EXP'' and than apply \verb/{'0; y => (parm x)}/.

The reparser will first use the PEG parser to reparse the string 
as an EXP with the special instruction that \verb/y/ is
an macro parameter.  This will then get parsed as
\verb/(exp (id x) (sym +) (mid y PARM))/.  The parser is able to recognize y
as a ``mid'' rather than a ``id'' because of the special \verb/MID/
production in the grammar:

\begin{code}[fontsize=\small]
...
EXP = <exp> {TOKEN}+;
TOKEN : "token" = 
      <<mid PARM>> {MID} / {BRACK} / {CONST} / <id> {ID} / <sym> {SYM} / PARAN;
...
MID : "macro identifier" = 
     {[@$\a_][\a_\d]*} SPACING;
\end{code}

That is when trying to match a token the MID production is tried, it
matches ``x'' but it is rejected because the special instruction
\verb/<<mid>>/ tells the PEG parser to reject the match unless the
string is in the list of possible macro identifiers.  However, when it
matches ``y'' it is accepted since ``y'' is in the list.  When an MID
matched the parser add the production where it matches as the
second argument which will be used latter.

After the string is parsed it will then apply the
\verb/{'0; y => (parm x)}/ instructions to the sub-parts.  This will
result in \verb/(exp'0 (id'0 x'0) (syn +) (id x))/.  That is marks are
applied to most of the symbols while \verb/(mid y TOKEN)/ becomes
\verb/(id x)/.  During the substitution the string, \verb/x/, is
reparsed as the production noted in the second argument of the
\verb/mid/, which in this case in ``TOKEN''.  Hence, \verb/x/ becomes
\verb/(id x)/.  \verb/(syn +)/ does not get a symbol because ``sym''
is a special case of a syntax form which does not get additional
processing, other forms include literal numbers, and strings.

The results of the reparse are then expanded and parsed as before,
with marks being used as described in the previous section, with the
additional rule that if no marks are left and a symbol is still not
found than it is assumed to be associated with a primitive form.  For
example ``exp'0'' and ``id'0'' will be assumed to represent the built
in ``exp'' macro and the ``id'' primitive since neither are in the
current environment.  Since the result is an ``exp'' it will be
expanded again to become \verb/(plus (id'0 x'0) (id x))/, 
which will than be converted into an AST.

In this case the result of the reparse is a fully parsed string, but
this is not always the case, for example if the macro instead expanded
to \verb/("()" "(x + 2) * y")/ the string will parse to
\verb/(exp ("()" "x + 2") (sym *) (mid y))/ and then become
\verb/(exp'0 ("()" "x + 2"){'0; y => (parm x)} (sym *) (id x))/, that
is if any unparsed string are encountered the instructions are simply
pushed down rather than being directly applied.

Another problem is dealing with the case in which the macro parameter
is not a TOKEN, for example if the call to foo was instead
\verb/foo(x + 2)/.  In order to handle this case mid's labeled to be
parsed as a TOKEN is really parsed as a PARM whose production is:

\begin{code}
\end{code}

NOW EXPLAIN HOW SYNTAX MACROS DIFFER.

ALSO EXPLAIN HOW MULTIPLE REPLACEMENT SETS ARE HANDLED.

\section{Bending Lexical Scope}

EXPLAIN get\_context and replace\_context.

EXPLAIN ``fluid\_*''.

\section{The Complete Macro ABI}

...

\end{document}


%% EXPANDING MACROS

%% A pattern matching macro consists of two parts.  The first part is to
%% match the paramaters of the macro with pattern variables and (known as
%% the match step), the second part is to replace and pattern variables
%% in the macro body with the paramaters matched in the previous step
%% (known as the replace step).

%% ...

%% Pattern variablies inside the replace string are known as macro
%% identifiers and are repsented as (mid <ID>)



%% During the replace step when an unparsed string is encountered it is
%% reparsed as ....  During the reparsing step macro identifers are
%% reconized by special productions in the grammer <<mid>> which matches
%% an identifier when this rule in encountered the matching identider is
%% checked againat a list of macro identifers in the current scope and if
%% it matches than is parsed as a (mid <ID>) otherwise the production is
%% ignored...


%% MISC


%% ----

%% parse_str(String how, String what) : Syntax
%%   Parses the string "what" with production "how" and returnes a syntax
%%   object representing the parsed string.  Does not expand.

%% parse_top(Syntax, Environ) : void
%%   Parses the top level.  Does not return a value, instead populates
%%   environment with the top level declarations.

%% main = parse_top(parse_str("TOP", <source file>))

%% ---



